{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Any, Union\n"
      ],
      "metadata": {
        "id": "CEO39SkMc3u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_df = pd.read_csv('/content/transactions_train.csv')\n",
        "transactions_df['t_dat'] = pd.to_datetime(transactions_df['t_dat'])\n",
        "customers_df = pd.read_csv('/content/customers.csv')\n",
        "articles_df = pd.read_csv('/content/articles.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKPQB1VmfrC2",
        "outputId": "45cfc7fd-f5b4-404c-ea10-f3d3a119183f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemFeatures(ABC):\n",
        "    @abstractmethod\n",
        "    def get(self, *args, **kwargs) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        article_id -> features\n",
        "        \"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "pIGdGfEUdA5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CategoryTransform(ItemFeatures):\n",
        "    \"\"\"\n",
        "    factorize all articles columns\n",
        "    \"\"\"\n",
        "    def __init__(self, articles_df: pd.DataFrame):\n",
        "        self.articles_df = articles_df\n",
        "\n",
        "    def get(self):\n",
        "        self.__feature_columns = list(filter(lambda x: 'name' in x, self.articles_df.columns))[1:]\n",
        "        filtered_articles = self.articles_df[self.__feature_columns]\n",
        "        filtered_articles = filtered_articles.apply(lambda x: pd.factorize(x)[0])\n",
        "        filtered_articles['article_id'] = self.articles_df['article_id']\n",
        "\n",
        "        features = filtered_articles.set_index('article_id').astype('int8')\n",
        "        return features\n",
        "\n",
        "    def get_columns(self):\n",
        "        return self.__feature_columns"
      ],
      "metadata": {
        "id": "ISc7EK-rdCTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AggrTransform(ItemFeatures):\n",
        "    \"\"\"\n",
        "    aggregation transactions features : mean, max and etc...\n",
        "    \"\"\"\n",
        "    def __init__(self, articles_df: pd.DataFrame, transactions_df: pd.DataFrame):\n",
        "        self.articles_df = articles_df\n",
        "        self.transactions_df = transactions_df\n",
        "\n",
        "    def get(self):\n",
        "        stats = self._get_stats()\n",
        "        return stats\n",
        "\n",
        "    def _get_stats(self):\n",
        "        transactions_more = self.transactions_df.merge(self.articles_df, on = ('article_id'))\n",
        "        grouped = (\n",
        "            transactions_more.\n",
        "            groupby('article_id')\n",
        "        )\n",
        "\n",
        "        counts = (\n",
        "            grouped['article_id']\n",
        "            .count()\n",
        "            .to_frame()\n",
        "            .rename(columns = {'article_id': 'count'})\n",
        "            .astype('int16')\n",
        "            .reset_index()\n",
        "            .set_index('article_id')\n",
        "        )\n",
        "        sums = (\n",
        "            grouped['price']\n",
        "            .sum()\n",
        "            .to_frame()\n",
        "            .astype('float32')\n",
        "            .rename(columns = {\n",
        "                'price': 'sum_price'\n",
        "            })\n",
        "        )\n",
        "        means = (\n",
        "            grouped['price']\n",
        "            .mean()\n",
        "            .to_frame()\n",
        "            .astype('float32')\n",
        "            .rename(columns = {\n",
        "                'price': 'mean_price'\n",
        "            })\n",
        "        )\n",
        "        mins = (\n",
        "            grouped['price']\n",
        "            .min()\n",
        "            .to_frame()\n",
        "            .astype('float32')\n",
        "            .rename(columns = {\n",
        "               'price': 'min_price'\n",
        "            })\n",
        "        )\n",
        "        maxs = (\n",
        "            grouped['price']\n",
        "            .max()\n",
        "            .to_frame()\n",
        "            .astype('float32')\n",
        "            .rename(columns = {\n",
        "                'price': 'max_price'\n",
        "            })\n",
        "        )\n",
        "\n",
        "        output_df = (\n",
        "            counts\n",
        "            .merge(sums, on = ('article_id'))\n",
        "            .merge(means, on = ('article_id'))\n",
        "            .merge(mins, on = ('article_id'))\n",
        "            .merge(maxs, on = ('article_id'))\n",
        "        )\n",
        "        return output_df"
      ],
      "metadata": {
        "id": "AArkehZhdETD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TopTransforms(ItemFeatures):\n",
        "    \"\"\"\n",
        "    whether category appears in top categories\n",
        "    \"\"\"\n",
        "    def __init__(self, articles_df: pd.DataFrame, topk = 3):\n",
        "        self.articles_df = articles_df\n",
        "        self.topk = topk\n",
        "\n",
        "    def get(self):\n",
        "        name_cols = list(filter(lambda x: 'name' in x, self.articles_df.columns))\n",
        "\n",
        "        value_counts = self._get_value_counts(name_cols)\n",
        "        value_counts = {\n",
        "            f'{k}_{self.topk}': self.articles_df[k].isin(v).astype('int8') for k, v in value_counts.items()\n",
        "        }\n",
        "\n",
        "        output_df = self.articles_df.assign(**value_counts)\n",
        "        output_df = output_df[['article_id'] + list(value_counts.keys())].set_index('article_id')\n",
        "        return output_df\n",
        "\n",
        "    def _get_value_counts(self, name_cols: List[str]):\n",
        "        value_counts = self.articles_df[name_cols].apply(pd.Series.value_counts)\n",
        "        get_index = lambda x: value_counts.sort_values(x, ascending = False)[x][:self.topk].index\n",
        "        value_counts = dict(zip(name_cols, map(lambda x: get_index(x), name_cols)))\n",
        "        return value_counts"
      ],
      "metadata": {
        "id": "YwSgmXuAdIRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsc2kb1WcyFB"
      },
      "outputs": [],
      "source": [
        "class ItemFeaturesCollector:\n",
        "    @staticmethod\n",
        "    def collect(features: Union[List[ItemFeatures], List[str]], **kwargs) -> pd.DataFrame:\n",
        "        output_df = None\n",
        "\n",
        "        for feature in tqdm(features):\n",
        "            if isinstance(feature, ItemFeatures):\n",
        "                feature_out = feature.get(**kwargs)\n",
        "            if isinstance(feature, str):\n",
        "                try:\n",
        "                    feature_out = pd.read_csv(feature)\n",
        "                except:\n",
        "                    feature_out = pd.read_parquet(feature)\n",
        "\n",
        "            if output_df is None:\n",
        "                output_df = feature_out\n",
        "            else:\n",
        "                output_df = output_df.merge(feature_out, on = ('article_id'))\n",
        "        return output_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_features = ItemFeaturesCollector.collect([\n",
        "    CategoryTransform(articles_df),\n",
        "    AggrTransform(articles_df, transactions_df),\n",
        "    TopTransforms(articles_df)\n",
        "])\n",
        "item_features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpJlkwIOnso",
        "outputId": "3a5956f7-3037-41d8-ae03-efa68b8b72da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 25.53it/s]\n"
          ]
        }
      ]
    }
  ]
}